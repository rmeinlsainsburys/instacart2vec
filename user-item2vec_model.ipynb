{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "# import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/Users/rico.meinl/Desktop/BACHELOR_THESIS/instacart2vec/source\")\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument, FAST_VERSION\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from source.item2vec_recommender import Item2VecRecommender\n",
    "from source.item2vec_embeddings import Item2VecEmbeddings\n",
    "from source.data_loader import DataLoader\n",
    "\n",
    "from source.baseline_recommender import MostPopularForUserRecommender\n",
    "\n",
    "from source.utils import convert_size\n",
    "\n",
    "# logging.basicConfig(\n",
    "#      format=\"%(levelname)s - %(asctime)s: %(message)s\",\n",
    "#      datefmt=\"%H:%M:%S\",\n",
    "#      level=logging.INFO,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = \"\"\n",
    "# small = \"small_\"\n",
    "algorithm = \"user-item2vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Metadata: False\n",
      "With User: True\n",
      "Loading data...\n",
      "Creating file to iterate for user-item2vec in sentences/user-item2vec/train.txt\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(algorithm=algorithm,\n",
    "                         small_data=(small!=\"\"),\n",
    "                         with_meta=False,\n",
    "                         with_user=True,\n",
    "                         use_file_iterator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_loader = load_data(small_data=(small!=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_data = data_loader[\"train\"]\n",
    "validation_data = data_loader[\"validation\"]\n",
    "test_data = data_loader[\"test\"]\n",
    "item_metadata = data_loader[\"metadata\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_user_item_interactions(train_data, n_items):\n",
    "    user_transactions_map = {}\n",
    "    user_item_frequency = {}\n",
    "    item_frequency = {}\n",
    "    for index, row in enumerate(train_data):\n",
    "        # user id is always first in list, then all the purchased items\n",
    "        user_id = row[0]\n",
    "        items = row[1:]\n",
    "        temp_transactions = user_transactions_map.get(user_id, [])\n",
    "        temp_transactions.append(index)\n",
    "        user_transactions_map[user_id] = temp_transactions\n",
    "\n",
    "        temp_item_frequency = user_item_frequency.get(user_id, {})\n",
    "        for item in items:\n",
    "            temp_item_frequency[item] = temp_item_frequency.get(item, 0) + 1\n",
    "            item_frequency[item] = item_frequency.get(item, 0) + 1\n",
    "        user_item_frequency[user_id] = temp_item_frequency\n",
    "        \n",
    "\n",
    "    return user_transactions_map, user_item_frequency, item_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create product key conversion if not exists\n",
    "product_key_conversion = get_product_key_conversion(item_metadata)\n",
    "print(product_key_to_meta(product_key_conversion, \"1\"))\n",
    "print(product_key_to_name(product_key_conversion, \"1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_sentences(data, stage, is_np_array=True, overwrite=True):\n",
    "    # Build train set\n",
    "    filepath = f\"sentences/{algorithm}/{stage}.txt\"\n",
    "    if overwrite:\n",
    "        print(\n",
    "            f\"Creating sentences for the {stage} stage for {algorithm} in {filepath}\"\n",
    "        )\n",
    "        with open(filepath, \"w\") as file:\n",
    "            if is_np_array:\n",
    "                for transaction in data:\n",
    "                    # as this is user_item2vec, also include the user\n",
    "                    if len(transaction) > 0:\n",
    "                        file.write(\" \".join(map(str, transaction)) + \"\\n\")\n",
    "            else:\n",
    "                print(\"Not defined as of now. Please implement.\")\n",
    "#                 for i, row in data.iterrows():\n",
    "#                     file.write(' '.join(map(str, row[\"product_id\"])) + \"\\n\")\n",
    "                \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class SentenceIterator(object):\n",
    "    def __init__(self, sentences_filepath):\n",
    "        self.sentences_filepath = sentences_filepath\n",
    "                    \n",
    "    def __iter__(self):\n",
    "        assert os.path.exists(self.sentences_filepath)\n",
    "        for line in open(self.sentences_filepath):\n",
    "            transaction = line.split()\n",
    "            # user is always first: transaction[0] so feed it as tags, items are transaction[1:]\n",
    "            yield TaggedDocument(words=transaction[1:], tags=[transaction[0]])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train_sentences_path = create_sentences(train_data, \"train\", overwrite=False)\n",
    "train_sentences_path = create_sentences(train_data, f\"{small}train\", is_np_array=True, overwrite=True)\n",
    "train_sentences = SentenceIterator(sentences_filepath=train_sentences_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        train_data,\n",
    "        epochs,\n",
    "        embedding_size,\n",
    "        window_size,\n",
    "        ns_exponent,\n",
    "        number_of_negative_samples,\n",
    "        min_count,\n",
    "        sample,\n",
    "        save=False,\n",
    "    ):\n",
    "\n",
    "        # PV-DBOW: dm=0, dbow_words=1\n",
    "        # PV-DM modes without concatenation dm=1, dm_concat=0\n",
    "        model = Doc2Vec(\n",
    "            documents=train_data,\n",
    "            dm= 0,# 1,\n",
    "            # dm_mean=1, # if 0, it uses sum of context vectors instead of average\n",
    "            # dm_concat=0,\n",
    "            dbow_words=1, # if 1 it trains word vectors as well, if 0 it only trains doc vectors\n",
    "            vector_size=embedding_size,\n",
    "            window=window_size,\n",
    "            min_count=min_count,\n",
    "            compute_loss=True,\n",
    "            workers=multiprocessing.cpu_count(),\n",
    "            hs=0,\n",
    "            sample=sample,\n",
    "            negative=number_of_negative_samples,\n",
    "            ns_exponent=ns_exponent,\n",
    "            epochs=epochs,\n",
    "        )\n",
    "        \n",
    "        model.init_sims(replace=True)\n",
    "\n",
    "        if save:\n",
    "            model.save(f\"models/{algorithm}/embeddings.model\")\n",
    "            print(\"Model Saved\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Doc2Vec model...\n"
     ]
    }
   ],
   "source": [
    "embeddings = Item2VecEmbeddings(algorithm=\"user-item2vec\",\n",
    "                                product_key_conversion=data_loader.product_key_conversion,\n",
    "                                with_meta=False,\n",
    "                                with_user=True)\n",
    "\n",
    "embeddings.load_model(model_path=f\"models/{algorithm}/embeddings.model\")\n",
    "\n",
    "# embeddings.train_model(\n",
    "#                         data_loader.train_data_iterator,\n",
    "#                         epochs=15,\n",
    "#                         embedding_size=128,\n",
    "#                         window_size=5, # 100,\n",
    "#                         min_count=10,\n",
    "#                         number_of_negative_samples=7,\n",
    "#                         sample=0.01,\n",
    "#                         ns_exponent=0.5,\n",
    "#                         save=False,\n",
    "#                     )\n",
    "\n",
    "# model = train_model(\n",
    "#                     train_sentences,\n",
    "#                     epochs=1,\n",
    "#                     embedding_size=128,\n",
    "#                     window_size=100,\n",
    "#                     min_count=10,\n",
    "#                     number_of_negative_samples=7,\n",
    "#                     sample=0.01,\n",
    "#                     ns_exponent=0.5,\n",
    "#                     save=True,\n",
    "#                 )\n",
    "\n",
    "# model = Doc2Vec.load(f\"models/{algorithm}/embeddings.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a matrix filled with embeddings of all items considered.\n",
    "mapping = {item_key: index for index, item_key in enumerate(model.wv.index2word)}\n",
    "mapping_back = {index: item_key for item_key, index in mapping.items()}\n",
    "embedding = [model.wv[key] for key in mapping.keys()]\n",
    "\n",
    "# embedding = [model.wv[key] for key in model.wv.vocab.keys()]\n",
    "# context_vectors = [vector for vector in model.trainables.syn1neg]\n",
    "# mapping = {elem: i for i, elem in enumerate(model.wv.vocab.keys())}\n",
    "# mapping_back = {v: k for k, v in mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_category_list = []\n",
    "y_aisle_list = []\n",
    "        \n",
    "for key in model.wv.vocab.keys():\n",
    "    y_category_list.append(product_key_to_meta(product_key_conversion, key).split(\"\\t\")[1])\n",
    "    y_aisle_list.append(product_key_to_meta(product_key_conversion, key).split(\"\\t\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_category_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_aisle_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category and Aisle Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_labels(classifier, x, y, test_size=0.5):\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=0)\n",
    "\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_predictions = classifier.predict(x_test)\n",
    "\n",
    "    # accuracy = round(accuracy_score(y_predictions, y_test), 3)\n",
    "    # precision = round(precision_score(y_predictions, y_test, average=\"weighted\"), 3)\n",
    "    # recall = round(recall_score(y_predictions, y_test, average=\"weighted\"), 3)\n",
    "    f1_micro = round(f1_score(y_predictions, y_test, average=\"micro\"), 4)\n",
    "    f1_macro = round(f1_score(y_predictions, y_test, average=\"macro\"), 4)\n",
    "    f1_weighted = round(f1_score(y_predictions, y_test, average=\"weighted\"), 4)\n",
    "\n",
    "    return f1_micro, f1_macro, f1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "k_neighbors = 10\n",
    "k_neighbors_classifier = KNeighborsClassifier(n_neighbors=k_neighbors, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_f1, aisle_f1 = embeddings.evaluate_embeddings(k_neighbors=10)\n",
    "\n",
    "# category_f1 = predict_labels(classifier=k_neighbors_classifier, x=embedding, y=y_category_list)\n",
    "# aisle_f1 = predict_labels(classifier=k_neighbors_classifier, x=embedding, y=y_aisle_list)\n",
    "\n",
    "# print(f\"Micro: {category_f1[0]}, Macro: {category_f1[1]}, Weighted: {category_f1[2]}\")\n",
    "# print(f\"Micro: {aisle_f1[0]}, Macro: {aisle_f1[1]}, Weighted: {aisle_f1[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Small Data\n",
    "# 5 epochs (64 dims)\n",
    "# Micro: 0.5179, Macro: 0.3083, Weighted: 0.567\n",
    "# Micro: 0.3111, Macro: 0.1314, Weighted: 0.367\n",
    "\n",
    "# # 5 epochs (32 dims)\n",
    "# Micro: 0.559, Macro: 0.3312, Weighted: 0.6019\n",
    "# Micro: 0.3231, Macro: 0.1447, Weighted: 0.3697\n",
    "\n",
    "# 5 epochs (128 dims)\n",
    "# Micro: 0.4068, Macro: 0.1842, Weighted: 0.4701\n",
    "# Micro: 0.2479, Macro: 0.1, Weighted: 0.3145\n",
    "\n",
    "# 5 epochs (128 dims) using model.init_sims()\n",
    "# Micro: 0.5846, Macro: 0.3872, Weighted: 0.6137\n",
    "# Micro: 0.3487, Macro: 0.1544, Weighted: 0.3917\n",
    "\n",
    "# 5 epochs (256 dims)\n",
    "# Micro: 0.3316, Macro: 0.1322, Weighted: 0.4191\n",
    "# Micro: 0.2017, Macro: 0.0816, Weighted: 0.265\n",
    "\n",
    "# 15 epochs\n",
    "# Micro: 0.4803, Macro: 0.2815, Weighted: 0.5265\n",
    "# Micro: 0.2974, Macro: 0.1203, Weighted: 0.3548\n",
    "\n",
    "# 25 epochs\n",
    "# Micro: 0.4855, Macro: 0.2555, Weighted: 0.5369\n",
    "# Micro: 0.3043, Macro: 0.1338, Weighted: 0.3557\n",
    "\n",
    "# 100 epochs\n",
    "# Micro: 0.4684, Macro: 0.2413, Weighted: 0.5284\n",
    "# Micro: 0.2923, Macro: 0.1236, Weighted: 0.3459"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST START: MOST POPULAR FOR USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "user_transactions_map, user_item_frequency, item_frequency = generate_user_item_interactions(train_data=train_data, \n",
    "                                                                                             n_items=n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "most_popular_for_user_baseline = MostPopularForUserRecommender(n_items=n_items, user_item_frequency=user_item_frequency, item_frequency=item_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Validation Set and Test Set\n",
    "k = 10\n",
    "hit_rate_at_k_val, ndcg_at_k_val = most_popular_for_user_baseline.evaluate(validation_data, k=k)\n",
    "print(f\"Hit Rate @ {k} on Validation Set: {hit_rate_at_k_val}\")\n",
    "print(f\"NDCG @ {k} on Validation Set: {ndcg_at_k_val}\")\n",
    "\n",
    "# hit_rate_at_k_test, ndcg_at_k_test = item2vec_recommender.evaluate(test_set, k=k)\n",
    "# print(f\"Hit Rate @ {k} on Test Set: {hit_rate_at_k_test}\")\n",
    "# print(f\"NDCG @ {k} on Test Set: {ndcg_at_k_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UserItem2Vec Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useritem2vec_recommender = Item2VecRecommender(algorithm=\"user-item2vec\", \n",
    "                                               item_key_mapping=embeddings.mapping, \n",
    "                                               user_item_frequency=data_loader.user_item_frequency,\n",
    "                                               embedding_vectors=embeddings.embedding_vectors, \n",
    "                                               context_vectors=embeddings.context_vectors, \n",
    "                                               user_vectors=embeddings.user_vectors)\n",
    "print(useritem2vec_recommender.context_vectors.shape)\n",
    "\n",
    "# useritem2vec_recommender = Item2VecRecommender(algorithm=\"user-item2vec\", \n",
    "#                                                item_key_mapping=mapping, \n",
    "#                                                user_item_frequency=user_item_frequency,\n",
    "#                                                embedding_vectors=model.wv.vectors, \n",
    "#                                                context_vectors=model.trainables.syn1neg, \n",
    "#                                                user_vectors=model.docvecs)\n",
    "# print(useritem2vec_recommender.context_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_closest_items_for_user(user_id):\n",
    "    most_similar = model.wv.most_similar([model.docvecs[user_id]], topn=10)\n",
    "    for item, similarity in most_similar:\n",
    "        print(f\"{product_key_to_name(item)} - {round(similarity, 3)}\")\n",
    "    print(\"\\n\")\n",
    "        \n",
    "def clone_get_closest_items_for_user(user_id):\n",
    "    user_distances = np.dot(_l2_norm(model.wv.vectors), _l2_norm(model.docvecs[user_id]))\n",
    "    user_candidate_list = argsort(user_distances, topn=10, reverse=True)\n",
    "    user_indices = [(model.wv.index2word[item], float(user_distances[item])) for item in user_candidate_list]\n",
    "    \n",
    "    for item, similarity in user_indices:\n",
    "        print(f\"{product_key_to_name(item)} - {round(similarity, 3)}\")\n",
    "        \n",
    "    print(\"\\n\")\n",
    "    \n",
    "def get_most_popular_for_user(user_id):\n",
    "    most_popular = list(OrderedDict(sorted(user_item_frequency[user_id].items(), key=lambda t: t[1], reverse=True)).items())\n",
    "    for item, occurences in most_popular[:10]:\n",
    "        print(f\"{product_key_to_name(item)} - {occurences}\")\n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "user_id = 'user_71' # 71, 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# get_closest_items_for_user(user_id)\n",
    "clone_get_closest_items_for_user(user_id)\n",
    "get_most_popular_for_user(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_context_vectors = model.trainables.syn1neg\n",
    "test_embedding = model.wv\n",
    "test_user_vector = model.docvecs\n",
    "user_id = validation_data[0][0]\n",
    "items = validation_data[0][1:]\n",
    "\n",
    "# First get the top complementary items\n",
    "test_item_embeddings = [model.wv[key] for key in items if key in model.wv]\n",
    "test_mean_basket_vector = np.mean(test_item_embeddings, 0)\n",
    "\n",
    "test_distances = np.dot(test_context_vectors, test_mean_basket_vector)\n",
    "\n",
    "test_candidate_list = argsort(test_distances, topn=100, reverse=True)\n",
    "        \n",
    "test_indices = [model.wv.index2word[item] for item in test_candidate_list]\n",
    "test_indices_index = {i: item for (i, item) in enumerate(test_indices)}\n",
    "\n",
    "# then rank the top items by distance to user (from largest to smallest)\n",
    "test_candidate_embeddings = [model.wv[key] for key in test_indices if key in model.wv]\n",
    "test_candidate_embeddings = np.array(test_candidate_embeddings)\n",
    "\n",
    "test_user_distances = np.dot(_l2_norm(test_candidate_embeddings), _l2_norm(test_user_vector[user_id]))\n",
    "test_user_candidate_list = argsort(test_user_distances, topn=10, reverse=True)\n",
    "test_user_indices = [test_indices_index[item] for item in test_user_candidate_list]\n",
    "\n",
    "# test_user_distances = np.dot(test_candidate_embeddings, test_user_vector[user_id])\n",
    "# test_user_candidate_list = argsort(test_user_distances, topn=20, reverse=True)\n",
    "# test_user_indices = [model.wv.index2word[item] for item in test_user_candidate_list]\n",
    "for item in test_user_indices:\n",
    "    print(f\"{product_key_to_name(item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from gensim.matutils import argsort\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# NOT NEEDED, init_sims does the job\n",
    "def _l2_norm(m, replace=False):\n",
    "        \"\"\" Return an L2-normalized version of a matrix. \"\"\"\n",
    "        dist = np.sqrt((m ** 2).sum(-1))[..., np.newaxis]\n",
    "        if replace:\n",
    "            m /= dist\n",
    "            return m\n",
    "        else:\n",
    "            return (m / dist).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_items(recommender, user_id, given_items, alpha):\n",
    "        candidate_list = []\n",
    "        # map the items word to its index\n",
    "        target_items = [\n",
    "            recommender.item_key_mapping[key]\n",
    "            if (isinstance(key, str) and key.startswith(\"product\"))\n",
    "            else key\n",
    "            for key in given_items\n",
    "        ]\n",
    "        # slice the word vectors array to only keep the relevant items\n",
    "        item_embeddings = recommender.embedding_vectors[target_items]\n",
    "\n",
    "        mean_basket_vector = np.mean(item_embeddings, 0)\n",
    "\n",
    "        # complementary items need to be calculated via dot product not cosine similarity\n",
    "        distances = np.dot(recommender.context_vectors, mean_basket_vector)\n",
    "        \n",
    "        user_distances = np.dot(recommender.embedding_vectors, recommender.user_vectors[user_id])\n",
    "                    \n",
    "        user_distances = min_max_scaling(x=user_distances, min_value=-2.5, max_value=2.5)\n",
    "\n",
    "        candidate_scores = (distances * (1 - alpha)) + (\n",
    "            user_distances * (alpha)\n",
    "        )\n",
    "\n",
    "        return candidate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transaction(recommender, user_id, given_items, test_items):\n",
    "        # get the predicted items and their scores\n",
    "        item_scores = predict_items(recommender, user_id=user_id, given_items=given_items)\n",
    "        # create a list of item scores\n",
    "        # predicted_item_scores = np.array(list(item_scores.values()))\n",
    "        # create a mapping for items to index in the scores list\n",
    "        # item_indices = {key: index for index, key in enumerate(item_scores.keys())}\n",
    "        \n",
    "        # separate the target items from the other items\n",
    "        negative_index = np.ones(recommender.n_items)\n",
    "        mask_items = [recommender.item_key_mapping[key] for key in test_items]\n",
    "        negative_index[mask_items] = 0\n",
    "        target_item_scores = item_scores[mask_items]\n",
    "        negative_items = item_scores[negative_index>0]\n",
    "        \n",
    "        # calculate the auc and ndcg\n",
    "        n_negative = len(negative_items)\n",
    "        false_predictions = (target_item_scores.reshape(1, len(target_item_scores)) <= negative_items.reshape(n_negative, 1)).sum(axis=0)\n",
    "        auc = (n_negative - false_predictions) / n_negative\n",
    "        ndcg = 1.0/np.log2(2 + false_predictions)\n",
    "        \n",
    "        return auc, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(recommender, test_transactions):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # more efficient than interating over numpy array\n",
    "        test_transactions = list(test_transactions)\n",
    "        metrics = []\n",
    "        min_transaction_items = 2\n",
    "        # after removing transactions with less than MIN_TRANSACTION_ITEMS\n",
    "        actual_transaction_length = len(test_transactions)\n",
    "        print(f\"{actual_transaction_length} transactions to evaluate.\")\n",
    "\n",
    "        \n",
    "        for test_transaction in test_transactions:\n",
    "            # user id is always first in list, then all the purchased items\n",
    "            user_id = test_transaction[0]\n",
    "            items = [item for item in test_transaction[1:] if item in recommender.item_key_mapping]\n",
    "            \n",
    "            if len(items) < min_transaction_items:\n",
    "                actual_transaction_length -= 1\n",
    "                continue\n",
    "\n",
    "            half = math.ceil(len(items) / 2)\n",
    "            basket_item_ids = items[:half]\n",
    "            hold_out_item_ids = items[half:]\n",
    "            \n",
    "            _auc, _ndcg = evaluate_transaction(recommender, user_id=user_id, given_items=basket_item_ids, test_items=hold_out_item_ids)\n",
    "            metrics.append([_auc.mean(), _ndcg.mean()])\n",
    "\n",
    "        actual_transaction_length = len(metrics)\n",
    "        metrics = np.array(metrics).mean(axis=0)\n",
    "        auc = round(metrics[0], 4)\n",
    "        ndcg= round(metrics[1], 4)\n",
    "\n",
    "        print(f\"Evaluated {actual_transaction_length} transactions.\")\n",
    "        print(f\"Took {round((time.time()-start_time)/60., 5)} minutes.\")\n",
    "\n",
    "        return auc, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Set and Test Set\n",
    "validation_auc, validation_ndcg = evaluate(useritem2vec_recommender, validation_data)\n",
    "print(f\"AUC on Validation Set: {validation_auc}\")\n",
    "print(f\"NDCG on Validation Set: {validation_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# alpha = 0 (solely focus on context)\n",
    "# AUC on Validation Set:  0.7909\n",
    "# NDCG on Validation Set: 0.2024\n",
    "\n",
    "# alpha = 0.25 (more focus on context)\n",
    "# AUC on Validation Set:  0.8038\n",
    "# NDCG on Validation Set: 0.2028\n",
    "\n",
    "# alpha = 0.4 (more focus on context)\n",
    "# AUC on Validation Set:  0.8137\n",
    "# NDCG on Validation Set: 0.2026\n",
    "\n",
    "# alpha = 0.5 (almost equal focus, though context vectors are dot product so they are bigger)\n",
    "# AUC on Validation Set:  0.8209\n",
    "# NDCG on Validation Set: 0.2014\n",
    "\n",
    "# alpha = 0.6 (more focus on user)\n",
    "# AUC on Validation Set:  0.8275\n",
    "# NDCG on Validation Set: 0.1987\n",
    "\n",
    "# alpha = 0.75 (more focus on user)\n",
    "# AUC on Validation Set:  0.8296\n",
    "# NDCG on Validation Set: 0.1885\n",
    "\n",
    "# alpha = 1 (solely focus on user)\n",
    "# AUC on Validation Set:  0.6976\n",
    "# NDCG on Validation Set: 0.1507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Baseline (without user vector)\n",
    "# Hit Rate @ 10 on Validation Set: 0.1627\n",
    "# NDCG @ 10 on Validation Set:     0.0914\n",
    "\n",
    "# Without l2_norm (not cosine similarity)\n",
    "# Hit Rate @ 10 on Validation Set: 0.0468\n",
    "# NDCG @ 10 on Validation Set: 0.0225\n",
    "    \n",
    "# With l2_norm (cosine similarity)\n",
    "# Hit Rate @ 10 on Validation Set: 0.0382\n",
    "# NDCG @ 10 on Validation Set: 0.0173\n",
    "\n",
    "# Hit Rate @ 10 on Validation Set: 0.0224\n",
    "# NDCG @ 10 on Validation Set: 0.0108\n",
    "\n",
    "# PV-DM method: Using the closest items for user\n",
    "# Hit Rate @ 10 on Validation Set: 0.0302\n",
    "# NDCG @ 10 on Validation Set: 0.0147\n",
    "\n",
    "# PV-DM method, Candidate Generation: 20, Ranking by Cosine Similarity to User Vector\n",
    "# Hit Rate @ 10 on Validation Set: 0.0844\n",
    "# NDCG @ 10 on Validation Set: 0.0391\n",
    "\n",
    "# PV-DBOW method: Using the closest items for user\n",
    "# Hit Rate @ 10 on Validation Set: 0.0962\n",
    "# NDCG @ 10 on Validation Set: 0.0501\n",
    "\n",
    "# PV-DBOW method: Candidate Generation: 20, Ranking by Cosine Similarity to User Vector\n",
    "# Hit Rate @ 10 on Validation Set: 0.1056\n",
    "# NDCG @ 10 on Validation Set: 0.0502\n",
    "\n",
    "# PV-DBOW method: Candidate Generation: 100, Ranking by Cosine Similarity to User Vector\n",
    "# Hit Rate @ 10 on Validation Set: 0.0839\n",
    "# NDCG @ 10 on Validation Set: 0.0423\n",
    "\n",
    "# PV-DBOW method: Candidate Generation: 200, Ranking by Cosine Similarity to User Vector\n",
    "# Hit Rate @ 10 on Validation Set: 0.0844\n",
    "# NDCG @ 10 on Validation Set: 0.0425"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST OVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195479 transactions.\n",
      "Took 15.686 minutes.\n",
      "AUC:              0.9552\n",
      "NDCG:             0.1544\n",
      "Recall at 10:     0.0777\n",
      "Precision at 10:  0.0332\n",
      "206209 transactions to evaluate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rico.meinl/opt/miniconda3/envs/instacart2vec/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/rico.meinl/opt/miniconda3/envs/instacart2vec/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/Users/rico.meinl/Desktop/BACHELOR_THESIS/instacart2vec/recommender.py:60: RuntimeWarning: invalid value encountered in less_equal\n",
      "  false_predictions = (target_item_scores.reshape(1, len(target_item_scores)) <= negative_items.reshape(n_negative, 1)).sum(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 195194 transactions.\n",
      "Took 25.01 minutes.\n",
      "AUC:              0.9672\n",
      "NDCG:             0.1802\n",
      "Recall at 10:     0.1124\n",
      "Precision at 10:  0.1041\n",
      "Alpha: 0.2\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195479 transactions.\n",
      "Took 22.31 minutes.\n",
      "AUC:              0.9574\n",
      "NDCG:             0.1547\n",
      "Recall at 10:     0.0775\n",
      "Precision at 10:  0.0332\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195194 transactions.\n",
      "Took 13.509 minutes.\n",
      "AUC:              0.9686\n",
      "NDCG:             0.18\n",
      "Recall at 10:     0.1114\n",
      "Precision at 10:  0.1046\n",
      "Alpha: 0.4\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195479 transactions.\n",
      "Took 11.108 minutes.\n",
      "AUC:              0.9595\n",
      "NDCG:             0.1541\n",
      "Recall at 10:     0.0751\n",
      "Precision at 10:  0.0326\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195194 transactions.\n",
      "Took 12.58 minutes.\n",
      "AUC:              0.9696\n",
      "NDCG:             0.1778\n",
      "Recall at 10:     0.1069\n",
      "Precision at 10:  0.1023\n",
      "Alpha: 0.5\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195479 transactions.\n",
      "Took 11.06 minutes.\n",
      "AUC:              0.96\n",
      "NDCG:             0.153\n",
      "Recall at 10:     0.0724\n",
      "Precision at 10:  0.0317\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195194 transactions.\n",
      "Took 12.727 minutes.\n",
      "AUC:              0.9693\n",
      "NDCG:             0.1756\n",
      "Recall at 10:     0.1021\n",
      "Precision at 10:  0.0985\n",
      "Alpha: 0.6\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195479 transactions.\n",
      "Took 10.784 minutes.\n",
      "AUC:              0.9593\n",
      "NDCG:             0.1505\n",
      "Recall at 10:     0.0681\n",
      "Precision at 10:  0.0299\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195194 transactions.\n",
      "Took 12.729 minutes.\n",
      "AUC:              0.9676\n",
      "NDCG:             0.1717\n",
      "Recall at 10:     0.0954\n",
      "Precision at 10:  0.092\n",
      "Alpha: 0.8\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195479 transactions.\n",
      "Took 10.791 minutes.\n",
      "AUC:              0.9431\n",
      "NDCG:             0.132\n",
      "Recall at 10:     0.0428\n",
      "Precision at 10:  0.0172\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195194 transactions.\n",
      "Took 12.72 minutes.\n",
      "AUC:              0.9491\n",
      "NDCG:             0.1443\n",
      "Recall at 10:     0.0571\n",
      "Precision at 10:  0.0503\n",
      "Alpha: 1.0\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195479 transactions.\n",
      "Took 11.019 minutes.\n",
      "AUC:              0.8088\n",
      "NDCG:             0.0939\n",
      "Recall at 10:     0.0111\n",
      "Precision at 10:  0.004\n",
      "206209 transactions to evaluate.\n",
      "Evaluated 195194 transactions.\n",
      "Took 12.56 minutes.\n",
      "AUC:              0.8185\n",
      "NDCG:             0.0966\n",
      "Recall at 10:     0.0141\n",
      "Precision at 10:  0.0114\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    print(f\"Alpha: {alpha}\")\n",
    "    useritem2vec_recommender = Item2VecRecommender(algorithm=\"user-item2vec\", \n",
    "                                                   item_key_mapping=embeddings.mapping, \n",
    "                                                   user_item_frequency=data_loader.user_item_frequency,\n",
    "                                                   embedding_vectors=embeddings.embedding_vectors, \n",
    "                                                   context_vectors=embeddings.context_vectors, \n",
    "                                                   user_vectors=embeddings.user_vectors,\n",
    "                                                   alpha=alpha)\n",
    "    \n",
    "    # Within Basket Recommendations\n",
    "    test_auc, test_ndcg, test_recall, test_precision = useritem2vec_recommender.evaluate(data_loader.validation_data, \n",
    "                                                                                     k=10, \n",
    "                                                                                     within_basket=True)\n",
    "    \n",
    "    # Next Basket Recommendations\n",
    "    val_auc, val_ndcg, val_recall, val_precision = useritem2vec_recommender.evaluate(data_loader.validation_data, \n",
    "                                                                                     k=10, \n",
    "                                                                                     within_basket=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Set and Test Set\n",
    "# Within Basket Recommendations\n",
    "val_auc, val_ndcg, val_recall, val_precision = useritem2vec_recommender.evaluate(data_loader.validation_data, \n",
    "                                                                                 k=10, \n",
    "                                                                                 within_basket=True)\n",
    "\n",
    "test_auc, test_ndcg, test_recall, test_precision = useritem2vec_recommender.evaluate(data_loader.test_data, \n",
    "                                                                                     k=10, \n",
    "                                                                                     within_basket=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Basket Recommendations\n",
    "val_auc, val_ndcg, val_recall, val_precision = useritem2vec_recommender.evaluate(data_loader.validation_data, \n",
    "                                                                             k=10, \n",
    "                                                                             within_basket=False)\n",
    "\n",
    "test_auc, test_ndcg, test_recall, test_precision = useritem2vec_recommender.evaluate(data_loader.test_data, \n",
    "                                                                                 k=10, \n",
    "                                                                                 within_basket=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_embedding_files_for_visualization(model):\n",
    "    \"\"\" Create embedding files for visualization \"\"\"\n",
    "\n",
    "    target_vectors_filepath = (f\"visualization/{algorithm}_target_vectors.tsv\")\n",
    "    target_metadata_filepath = (f\"visualization/{algorithm}_target_metadata.tsv\")\n",
    "\n",
    "    out_v = open(target_vectors_filepath, \"w\", encoding=\"utf-8\")\n",
    "    out_m = open(target_metadata_filepath, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    # Meta File Header\n",
    "    out_m.write(\"ProductName\\tCategory\\tAisle\" + \"\\n\")\n",
    "    \n",
    "    for key in model.wv.vocab.keys():\n",
    "        embedding_vector = model.wv[key]\n",
    "        # META Input\n",
    "        out_m.write(product_key_to_meta(key) + \"\\n\")\n",
    "        out_v.write(\"\\t\".join([str(x) for x in embedding_vector]) + \"\\n\")\n",
    "\n",
    "    out_v.close()\n",
    "    out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.create_embedding_files_for_visualization(product_key_conversion=product_key_conversion)\n",
    "# create_embedding_files_for_visualization(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv(f\"preprocessed_data/{small}order_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_embedding_files_for_visualization(model, users):\n",
    "    \"\"\" Create embedding files for visualization \"\"\"\n",
    "\n",
    "    target_user_vectors_filepath = (f\"visualization/{algorithm}_target_user_vectors.tsv\")\n",
    "    target_user_names_filepath = (f\"visualization/{algorithm}_target_user_names.tsv\")\n",
    "\n",
    "    out_v = open(target_user_vectors_filepath, \"w\", encoding=\"utf-8\")\n",
    "    out_m = open(target_user_names_filepath, \"w\", encoding=\"utf-8\")\n",
    "    \n",
    "    for user_id in users:\n",
    "        user_name = f\"user_{user_id}\"\n",
    "        if user_name in model.docvecs:\n",
    "            user_embedding_vector = model.docvecs[user_name]\n",
    "            # META Input\n",
    "            out_m.write(f\"{user_name} \\n\")\n",
    "            out_v.write(\"\\t\".join([str(x) for x in user_embedding_vector]) + \"\\n\")\n",
    "\n",
    "    out_v.close()\n",
    "    out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_user_embedding_files_for_visualization(model=embeddings.model, users=list(orders[\"user_id\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform\n",
    "# a hyperparameter search (300k models evaluated) on: the number of\n",
    "# epochs n (10 to 200 with step of +10), the window-size L (3, 7, 12, 15),\n",
    "# the sub-sampling parameter t (Eq. (2)) (10−5\n",
    "# to 10−1 with step of ×10), the negative sampling distribution parameter α (Eq. (3)) (−1.4\n",
    "# to 1.4 with step of +0.2), the embedding size (50 to 200 with a step\n",
    "# of 50), the number of negative samples (5 to 20 with a step of 5) and\n",
    "# the learning rate (0.0025 to 0.25 with a step of ×10). The marginal\n",
    "# benefit of including the 3 latter variables to the optimization is not\n",
    "# significant, with less than 2% in terms of performance. Thus, for\n",
    "# readability, we only focus on the influence of the 4 first hyperparameters and keep the other fixed to default values (respectively\n",
    "# 50, 5 and 0.025)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "\n",
    "# Most Popular \n",
    "# Hit Rate @ 10 on Validation Set: 0.0703 +/- 0.0006\n",
    "# Hit Rate @ 10 on Test Set:       0.0709 +/- 0.0004\n",
    "# NDCG @ 10 on Validation Set:     0.0389 +/- 0.0005\n",
    "# NDCG @ 10 on Test Set:           0.039 +/- 0.0002\n",
    "\n",
    "# Most Popular For User\n",
    "# Hit Rate @ 10 on Validation Set: 0.3043 +/- 0.0008\n",
    "# Hit Rate @ 10 on Test Set:       0.2804 +/- 0.0006\n",
    "# NDCG @ 10 on Validation Set:     0.1693 +/- 0.0003\n",
    "# NDCG @ 10 on Test Set:           0.1558 +/- 0.0005\n",
    "\n",
    "# Item Co-Count\n",
    "# Hit Rate @ 10 on Validation Set: 0.1071 +/- 0.0012\n",
    "# Hit Rate @ 10 on Test Set:       0.1072 +/- 0.0001\n",
    "# NDCG @ 10 on Validation Set:     0.0584 +/- 0.0007\n",
    "# NDCG @ 10 on Test Set:           0.0586 +/- 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [1]\n",
    "window_sizes = [100]\n",
    "samples = [0.01, 0.1] # 0.01\n",
    "ns_exponents = [0.25, 0.5, 0.75] # 0.5\n",
    "embedding_sizes = [128]\n",
    "numbers_of_negative_samples = [7, 14]\n",
    "\n",
    "numbers_of_candidates = [25, 100] \n",
    "k_neighbors = 10\n",
    "k_predictions = 10\n",
    "\n",
    "results = []\n",
    "\n",
    "for epoch in epochs:\n",
    "    for window_size in window_sizes:\n",
    "        for sample in samples:\n",
    "            for ns_exponent in ns_exponents:\n",
    "                for embedding_size in embedding_sizes:\n",
    "                    for number_of_negative_samples in numbers_of_negative_samples:\n",
    "                        start = time.time()\n",
    "                        print(f\"Epoch: {epoch}, Window Size: {window_size}, Sample: {sample}, NS Exponent: {ns_exponent}, Embedding Size: {embedding_size}, Number of Negative Samples: {number_of_negative_samples}\")\n",
    "\n",
    "                        train_sentences = SentenceIterator(sentences_filepath=train_sentences_path)\n",
    "\n",
    "                        # Train the model\n",
    "                        model = train_model(\n",
    "                                            train_sentences,\n",
    "                                            epochs=epoch,\n",
    "                                            embedding_size=embedding_size,\n",
    "                                            window_size=window_size,\n",
    "                                            min_count= 10,\n",
    "                                            number_of_negative_samples=number_of_negative_samples,\n",
    "                                            sample=sample,\n",
    "                                            ns_exponent=ns_exponent,\n",
    "                                            save=False,\n",
    "                                        )\n",
    "\n",
    "                        # Create a matrix filled with embeddings of all items considered.\n",
    "                        mapping = {item_key: index for index, item_key in enumerate(model.wv.index2word)}\n",
    "                        mapping_back = {index: item_key for item_key, index in mapping.items()}\n",
    "                        embedding = [model.wv[key] for key in mapping.keys()]\n",
    "\n",
    "                        y_category_list = []\n",
    "                        y_aisle_list = []\n",
    "\n",
    "                        for key in model.wv.vocab.keys():\n",
    "                            y_category_list.append(product_key_to_meta(key).split(\"\\t\")[1])\n",
    "                            y_aisle_list.append(product_key_to_meta(key).split(\"\\t\")[2])\n",
    "\n",
    "\n",
    "                        # K Neighbors Classifier\n",
    "                        k_neighbors_classifier = KNeighborsClassifier(n_neighbors=k_neighbors, n_jobs=-1)\n",
    "\n",
    "                        category_f1 = predict_labels(classifier=k_neighbors_classifier, x=embedding, y=y_category_list)\n",
    "                        aisle_f1 = predict_labels(classifier=k_neighbors_classifier, x=embedding, y=y_aisle_list)\n",
    "\n",
    "                        print(f\"Category - Micro: {category_f1[0]}, Macro: {category_f1[1]}, Weighted: {category_f1[2]}\")\n",
    "                        print(f\"Aisle    - Micro: {aisle_f1[0]}, Macro: {aisle_f1[1]}, Weighted: {aisle_f1[2]}\")\n",
    "\n",
    "                        # Recommender\n",
    "                        useritem2vec_recommender = UserItem2VecRecommender(algorithm=\"user-item2vec\", \n",
    "                                                                           item_key_mapping=mapping, \n",
    "                                                                           embedding=model.wv, \n",
    "                                                                           context_vectors=model.trainables.syn1neg, \n",
    "                                                                           user_vectors=model.docvecs)\n",
    "\n",
    "                        validation_auc, validation_ndcg = useritem2vec_recommender.evaluate(validation_data)\n",
    "                        print(f\"AUC on Validation Set: {validation_auc}\")\n",
    "                        print(f\"NDCG on Validation Set: {validation_ndcg}\")\n",
    "\n",
    "                        # test_auc, test_ndcg = useritem2vec_recommender.evaluate(test_data)\n",
    "                        # print(f\"AUC on Test Set: {test_auc}\")\n",
    "                        # print(f\"NDCG on Test Set: {test_ndcg}\")\n",
    "\n",
    "\n",
    "                        results.append((epoch, \n",
    "                                        window_size, \n",
    "                                        sample, \n",
    "                                        ns_exponent, \n",
    "                                        embedding_size,\n",
    "                                        number_of_negative_samples,\n",
    "                                        category_f1[0], \n",
    "                                        aisle_f1[0], \n",
    "                                        category_f1[1], \n",
    "                                        aisle_f1[1],\n",
    "                                        category_f1[2], \n",
    "                                        aisle_f1[2],\n",
    "                                        validation_auc, \n",
    "                                        validation_ndcg\n",
    "                                       ))\n",
    "\n",
    "                        with open('parameter_search.txt', 'w') as f:\n",
    "                            for line in results:\n",
    "                                f.write(f\"{str(line)}\\n\")\n",
    "\n",
    "\n",
    "                        end = time.time()\n",
    "                        print(f\"Took {end - start} seconds\\n\")\n",
    "\n",
    "results.sort(key=lambda x: x[12], reverse=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "with open(f'results/{algorithm}_parameter_search.txt', 'r') as f:\n",
    "    results = f.readlines()\n",
    "    results = [eval(p.strip()) for p in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\n",
    "                                            \"Epoch\", \n",
    "                                            \"Window Size\", \n",
    "                                            \"Sample\",\n",
    "                                            \"NS Exponent\", \n",
    "                                            \"Embedding Size\", \n",
    "                                            \"Number of Negative Samples\",\n",
    "                                            \"F1 Macro Category\",\n",
    "                                            \"F1 Macro Aisle\",\n",
    "                                            \"F1 Micro Category\",\n",
    "                                            \"F1 Micro Aisle\",\n",
    "                                            \"Within-basket AUC\",\n",
    "                                            \"Within-basket NDCG\",\n",
    "                                            \"Within-basket Recall\",\n",
    "                                            \"Within-basket Precision\",\n",
    "                                            \"Next-basket AUC\",\n",
    "                                            \"Next-basket NDCG\",\n",
    "                                            \"Next-basket Recall\",\n",
    "                                            \"Next-basket Precision\"\n",
    "                                          ])\n",
    "results_df.to_csv(f'results/{algorithm}/{small}results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.read_csv(f'results/{algorithm}/{small}results.csv')\n",
    "# results_df.sort_values(\"Sample\", ascending=False)\n",
    "column = \"Number of Negative Samples\"\n",
    "\n",
    "print(results_df.groupby(column)[[\"Within-basket AUC\", \"Next-basket AUC\", \"Within-basket NDCG\", \"Next-basket NDCG\", \"Within-basket Recall\", \"Next-basket Recall\"]].mean())\n",
    "print(\"\\n#########################\\n\")\n",
    "print(results_df.groupby(column)[[\"Within-basket AUC\", \"Next-basket AUC\", \"Within-basket NDCG\", \"Next-basket NDCG\", \"Within-basket Recall\", \"Next-basket Recall\"]].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = results_df.corr(method='spearman')\n",
    "correlation.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"Avg. Recall\"] = (results_df[\"Within-basket Recall\"] + results_df[\"Next-basket Recall\"]) /2\n",
    "results_df.sort_values(\"Avg. Recall\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instacart2vec",
   "language": "python",
   "name": "instacart2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
